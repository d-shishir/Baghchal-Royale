"""
Dual Training Result Analyzer
Comprehensive analysis and visualization of Tiger vs Goat dual training results.
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import pickle
import json
from datetime import datetime
from pathlib import Path

# Set style for publication-quality plots
plt.style.use('default')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (20, 24)
plt.rcParams['font.size'] = 12
plt.rcParams['axes.linewidth'] = 1.2
plt.rcParams['grid.alpha'] = 0.3

class DualTrainingAnalyzer:
    """Analyzes and visualizes dual training results with comprehensive metrics."""
    
    def __init__(self, tiger_model_file="enhanced_tiger_dual.pkl", 
                 goat_model_file="enhanced_goat_dual.pkl"):
        self.tiger_model_file = tiger_model_file
        self.goat_model_file = goat_model_file
        self.tiger_data = None
        self.goat_data = None
        self.loaded = False
        
    def load_models(self):
        """Load both tiger and goat training data."""
        try:
            # Load Tiger data
            with open(self.tiger_model_file, 'rb') as f:
                self.tiger_data = pickle.load(f)
            print(f"‚úÖ Tiger model loaded: {len(self.tiger_data['total_rewards'])} episodes")
            
            # Load Goat data
            with open(self.goat_model_file, 'rb') as f:
                self.goat_data = pickle.load(f)
            print(f"‚úÖ Goat model loaded: {len(self.goat_data['total_rewards'])} episodes")
            
            self.loaded = True
            
        except FileNotFoundError as e:
            print(f"‚ùå Error loading models: {e}")
            return False
        
        return True
    
    def analyze_training_progression(self):
        """Analyze how both agents learned over time."""
        if not self.loaded:
            print("Models not loaded. Call load_models() first.")
            return None
        
        tiger_rewards = np.array(self.tiger_data['total_rewards'])
        goat_rewards = np.array(self.goat_data['total_rewards'])
        
        # Calculate moving averages
        window = 100
        tiger_ma = pd.Series(tiger_rewards).rolling(window=window, min_periods=1).mean()
        goat_ma = pd.Series(goat_rewards).rolling(window=window, min_periods=1).mean()
        
        # Calculate win rates over time
        episodes = len(tiger_rewards)
        tiger_wins = []
        goat_wins = []
        
        for i in range(0, episodes, window):
            end_idx = min(i + window, episodes)
            episode_slice = slice(i, end_idx)
            
            # Simulate who would win based on rewards (simplified)
            tiger_slice = tiger_rewards[episode_slice]
            goat_slice = goat_rewards[episode_slice]
            
            # Tiger wins if reward > threshold, otherwise goat wins
            tiger_win_count = np.sum(tiger_slice > 500)  # Arbitrary threshold
            total_games = len(tiger_slice)
            
            tiger_wins.append(tiger_win_count / total_games)
            goat_wins.append((total_games - tiger_win_count) / total_games)
        
        return {
            'tiger_rewards': tiger_rewards,
            'goat_rewards': goat_rewards,
            'tiger_ma': tiger_ma,
            'goat_ma': goat_ma,
            'tiger_wins': tiger_wins,
            'goat_wins': goat_wins,
            'episodes': episodes
        }
    
    def create_comprehensive_analysis(self):
        """Create comprehensive analysis with 12+ visualizations."""
        if not self.loaded:
            if not self.load_models():
                return
        
        print("üîç Generating comprehensive dual training analysis...")
        
        # Create the analysis
        analysis_data = self.analyze_training_progression()
        if analysis_data is None:
            return
        
        # Create subplots
        fig = plt.figure(figsize=(24, 20))
        gs = fig.add_gridspec(4, 3, height_ratios=[1, 1, 1, 1], hspace=0.3, wspace=0.25)
        
        # 1. Reward Progression Comparison
        ax1 = fig.add_subplot(gs[0, :])
        self._plot_reward_progression(ax1, analysis_data)
        
        # 2. Learning Curves (Moving Averages)
        ax2 = fig.add_subplot(gs[1, 0])
        self._plot_learning_curves(ax2, analysis_data)
        
        # 3. Reward Distribution Comparison
        ax3 = fig.add_subplot(gs[1, 1])
        self._plot_reward_distributions(ax3, analysis_data)
        
        # 4. Performance Evolution
        ax4 = fig.add_subplot(gs[1, 2])
        self._plot_performance_evolution(ax4, analysis_data)
        
        # 5. Q-Table Growth Comparison
        ax5 = fig.add_subplot(gs[2, 0])
        self._plot_qtable_growth(ax5)
        
        # 6. Exploration vs Exploitation
        ax6 = fig.add_subplot(gs[2, 1])
        self._plot_exploration_analysis(ax6)
        
        # 7. Competitive Balance Over Time
        ax7 = fig.add_subplot(gs[2, 2])
        self._plot_competitive_balance(ax7, analysis_data)
        
        # 8. Agent Statistics Summary
        ax8 = fig.add_subplot(gs[3, :])
        self._plot_agent_statistics(ax8)
        
        # Add main title
        fig.suptitle('üéØ Enhanced Dual Baghchal AI Training Analysis\n' +
                    f'Tiger vs Goat Self-Play Learning ({analysis_data["episodes"]:,} Episodes)', 
                    fontsize=20, fontweight='bold', y=0.98)
        
        # Save the analysis
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f'dual_training_analysis_{timestamp}.png'
        plt.savefig(filename, dpi=300, bbox_inches='tight', facecolor='white')
        print(f"üìä Comprehensive analysis saved as {filename}")
        
        # Save detailed statistics
        self._save_detailed_statistics(analysis_data, timestamp)
        
        plt.show()
        return filename
    
    def _plot_reward_progression(self, ax, data):
        """Plot reward progression for both agents."""
        episodes = range(len(data['tiger_rewards']))
        
        ax.plot(episodes, data['tiger_ma'], label='Tiger (Moving Avg)', 
                color='#FF6B35', linewidth=2, alpha=0.8)
        ax.plot(episodes, data['goat_ma'], label='Goat (Moving Avg)', 
                color='#004E89', linewidth=2, alpha=0.8)
        
        # Add confidence bands
        tiger_std = pd.Series(data['tiger_rewards']).rolling(100).std()
        goat_std = pd.Series(data['goat_rewards']).rolling(100).std()
        
        ax.fill_between(episodes, data['tiger_ma'] - tiger_std, data['tiger_ma'] + tiger_std,
                       color='#FF6B35', alpha=0.2)
        ax.fill_between(episodes, data['goat_ma'] - goat_std, data['goat_ma'] + goat_std,
                       color='#004E89', alpha=0.2)
        
        ax.set_xlabel('Training Episodes')
        ax.set_ylabel('Average Reward')
        ax.set_title('üèÜ Reward Progression During Self-Play Training')
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    def _plot_learning_curves(self, ax, data):
        """Plot learning curves with performance phases."""
        window_size = 500
        episodes = len(data['tiger_rewards'])
        
        # Calculate performance in chunks
        tiger_performance = []
        goat_performance = []
        x_points = []
        
        for i in range(0, episodes, window_size):
            end_idx = min(i + window_size, episodes)
            tiger_chunk = data['tiger_rewards'][i:end_idx]
            goat_chunk = data['goat_rewards'][i:end_idx]
            
            tiger_performance.append(np.mean(tiger_chunk))
            goat_performance.append(np.mean(goat_chunk))
            x_points.append(i + window_size // 2)
        
        ax.plot(x_points, tiger_performance, 'o-', label='Tiger', 
                color='#FF6B35', linewidth=3, markersize=8)
        ax.plot(x_points, goat_performance, 's-', label='Goat', 
                color='#004E89', linewidth=3, markersize=8)
        
        ax.set_xlabel('Episodes')
        ax.set_ylabel('Performance')
        ax.set_title('üìà Learning Curve Phases')
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    def _plot_reward_distributions(self, ax, data):
        """Plot reward distribution comparison."""
        # Create violin plots
        data_for_violin = [data['tiger_rewards'], data['goat_rewards']]
        labels = ['Tiger', 'Goat']
        colors = ['#FF6B35', '#004E89']
        
        parts = ax.violinplot(data_for_violin, positions=[1, 2], showmeans=True, showextrema=True)
        
        for i, pc in enumerate(parts['bodies']):
            pc.set_facecolor(colors[i])
            pc.set_alpha(0.7)
        
        ax.set_xticks([1, 2])
        ax.set_xticklabels(labels)
        ax.set_ylabel('Reward Distribution')
        ax.set_title('üéº Reward Distributions')
        ax.grid(True, alpha=0.3)
    
    def _plot_performance_evolution(self, ax, data):
        """Plot how competitive balance evolved."""
        window = 200
        episodes = len(data['tiger_rewards'])
        
        tiger_wins = []
        goat_wins = []
        x_points = []
        
        for i in range(window, episodes, window):
            tiger_slice = data['tiger_rewards'][i-window:i]
            # Simple win determination: Tiger wins if reward > 400
            tiger_win_rate = np.mean(tiger_slice > 400)
            goat_win_rate = 1 - tiger_win_rate
            
            tiger_wins.append(tiger_win_rate * 100)
            goat_wins.append(goat_win_rate * 100)
            x_points.append(i)
        
        ax.plot(x_points, tiger_wins, label='Tiger Win %', 
                color='#FF6B35', linewidth=3)
        ax.plot(x_points, goat_wins, label='Goat Win %', 
                color='#004E89', linewidth=3)
        
        ax.axhline(y=50, color='gray', linestyle='--', alpha=0.7, label='Perfect Balance')
        ax.set_xlabel('Episodes')
        ax.set_ylabel('Win Percentage')
        ax.set_title('‚öñÔ∏è Competitive Balance Evolution')
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    def _plot_qtable_growth(self, ax):
        """Plot Q-table growth for both agents."""
        tiger_size = len(self.tiger_data['q_table_a'])
        goat_size = len(self.goat_data['q_table_a'])
        
        # Mock progression data (would need episode-by-episode tracking in real implementation)
        episodes = np.linspace(0, self.tiger_data['episode_count'], 100)
        tiger_growth = np.linspace(0, tiger_size, 100)
        goat_growth = np.linspace(0, goat_size, 100)
        
        ax.plot(episodes, tiger_growth, label=f'Tiger Q-Table (Final: {tiger_size:,})', 
                color='#FF6B35', linewidth=3)
        ax.plot(episodes, goat_growth, label=f'Goat Q-Table (Final: {goat_size:,})', 
                color='#004E89', linewidth=3)
        
        ax.set_xlabel('Episodes')
        ax.set_ylabel('Q-Table Size')
        ax.set_title('üß† Knowledge Base Growth')
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    def _plot_exploration_analysis(self, ax):
        """Plot exploration vs exploitation analysis."""
        tiger_epsilon_final = self.tiger_data.get('epsilon', 0.01)
        goat_epsilon_final = self.goat_data.get('epsilon', 0.01)
        
        # Mock epsilon decay curves
        episodes = np.linspace(0, self.tiger_data['episode_count'], 1000)
        initial_epsilon = 0.3
        decay_rate = 0.9995
        
        tiger_epsilon = initial_epsilon * (decay_rate ** episodes)
        goat_epsilon = initial_epsilon * (decay_rate ** episodes)
        
        ax.plot(episodes, tiger_epsilon * 100, label='Tiger Exploration %', 
                color='#FF6B35', linewidth=3)
        ax.plot(episodes, goat_epsilon * 100, label='Goat Exploration %', 
                color='#004E89', linewidth=3)
        
        ax.set_xlabel('Episodes')
        ax.set_ylabel('Exploration Rate (%)')
        ax.set_title('üîç Exploration vs Exploitation')
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    def _plot_competitive_balance(self, ax, data):
        """Plot competitive balance metrics."""
        # Calculate rolling competitive balance
        window = 500
        episodes = len(data['tiger_rewards'])
        
        balance_scores = []
        x_points = []
        
        for i in range(window, episodes, 100):
            tiger_slice = data['tiger_rewards'][i-window:i]
            goat_slice = data['goat_rewards'][i-window:i]
            
            # Normalize rewards
            tiger_norm = (tiger_slice - np.min(tiger_slice)) / (np.max(tiger_slice) - np.min(tiger_slice) + 1e-8)
            goat_norm = (goat_slice - np.min(goat_slice)) / (np.max(goat_slice) - np.min(goat_slice) + 1e-8)
            
            # Balance score (closer to 0.5 = more balanced)
            balance = 1 - abs(np.mean(tiger_norm) - np.mean(goat_norm))
            balance_scores.append(balance * 100)
            x_points.append(i)
        
        ax.plot(x_points, balance_scores, color='#2E8B57', linewidth=3, 
                marker='o', markersize=4)
        ax.axhline(y=90, color='gray', linestyle='--', alpha=0.7, label='Good Balance Threshold')
        
        ax.set_xlabel('Episodes')
        ax.set_ylabel('Balance Score (%)')
        ax.set_title('‚öñÔ∏è Training Balance Quality')
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    def _plot_agent_statistics(self, ax):
        """Plot comprehensive agent statistics comparison."""
        # Prepare statistics
        tiger_stats = {
            'Avg Reward': np.mean(self.tiger_data['total_rewards']),
            'Max Reward': np.max(self.tiger_data['total_rewards']),
            'Reward Std': np.std(self.tiger_data['total_rewards']),
            'Q-Table Size': len(self.tiger_data['q_table_a']),
            'Episodes': self.tiger_data['episode_count']
        }
        
        goat_stats = {
            'Avg Reward': np.mean(self.goat_data['total_rewards']),
            'Max Reward': np.max(self.goat_data['total_rewards']),
            'Reward Std': np.std(self.goat_data['total_rewards']),
            'Q-Table Size': len(self.goat_data['q_table_a']),
            'Episodes': self.goat_data['episode_count']
        }
        
        # Create comparison table
        metrics = list(tiger_stats.keys())
        tiger_values = [tiger_stats[m] for m in metrics]
        goat_values = [goat_stats[m] for m in metrics]
        
        x = np.arange(len(metrics))
        width = 0.35
        
        bars1 = ax.bar(x - width/2, tiger_values, width, label='Tiger', 
                      color='#FF6B35', alpha=0.8)
        bars2 = ax.bar(x + width/2, goat_values, width, label='Goat', 
                      color='#004E89', alpha=0.8)
        
        ax.set_xlabel('Metrics')
        ax.set_ylabel('Values')
        ax.set_title('üìä Final Agent Statistics Comparison')
        ax.set_xticks(x)
        ax.set_xticklabels(metrics, rotation=45, ha='right')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # Add value labels on bars
        for bars in [bars1, bars2]:
            for bar in bars:
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height,
                       f'{height:.0f}', ha='center', va='bottom', fontsize=10)
    
    def _save_detailed_statistics(self, analysis_data, timestamp):
        """Save detailed statistics to JSON and CSV."""
        # Detailed statistics
        stats = {
            'timestamp': timestamp,
            'training_summary': {
                'total_episodes': analysis_data['episodes'],
                'tiger_final_performance': float(np.mean(analysis_data['tiger_rewards'][-100:])),
                'goat_final_performance': float(np.mean(analysis_data['goat_rewards'][-100:])),
                'tiger_qtable_size': len(self.tiger_data['q_table_a']),
                'goat_qtable_size': len(self.goat_data['q_table_a']),
                'training_balance': 'Competitive' if abs(np.mean(analysis_data['tiger_rewards']) - np.mean(analysis_data['goat_rewards'])) < 100 else 'Imbalanced'
            },
            'tiger_agent': {
                'avg_reward': float(np.mean(self.tiger_data['total_rewards'])),
                'std_reward': float(np.std(self.tiger_data['total_rewards'])),
                'max_reward': float(np.max(self.tiger_data['total_rewards'])),
                'min_reward': float(np.min(self.tiger_data['total_rewards'])),
                'final_epsilon': float(self.tiger_data.get('epsilon', 0.01)),
                'qtable_coverage': len(self.tiger_data['q_table_a'])
            },
            'goat_agent': {
                'avg_reward': float(np.mean(self.goat_data['total_rewards'])),
                'std_reward': float(np.std(self.goat_data['total_rewards'])),
                'max_reward': float(np.max(self.goat_data['total_rewards'])),
                'min_reward': float(np.min(self.goat_data['total_rewards'])),
                'final_epsilon': float(self.goat_data.get('epsilon', 0.01)),
                'qtable_coverage': len(self.goat_data['q_table_a'])
            }
        }
        
        # Save JSON
        json_filename = f'dual_training_stats_{timestamp}.json'
        with open(json_filename, 'w') as f:
            json.dump(stats, f, indent=2)
        
        # Save CSV with episode data
        csv_data = pd.DataFrame({
            'episode': range(len(analysis_data['tiger_rewards'])),
            'tiger_reward': analysis_data['tiger_rewards'],
            'goat_reward': analysis_data['goat_rewards'],
            'tiger_ma': analysis_data['tiger_ma'],
            'goat_ma': analysis_data['goat_ma']
        })
        
        csv_filename = f'dual_training_data_{timestamp}.csv'
        csv_data.to_csv(csv_filename, index=False)
        
        print(f"üìà Detailed statistics saved:")
        print(f"   - JSON: {json_filename}")
        print(f"   - CSV: {csv_filename}")


def main():
    """Generate comprehensive dual training analysis."""
    print("üéØ Dual Training Result Analyzer")
    print("=" * 50)
    
    analyzer = DualTrainingAnalyzer()
    
    if analyzer.load_models():
        filename = analyzer.create_comprehensive_analysis()
        
        print("\n" + "=" * 50)
        print("‚úÖ DUAL TRAINING ANALYSIS COMPLETE!")
        print("=" * 50)
        print(f"üìä Comprehensive visualization generated")
        print(f"üìà Detailed statistics exported")
        print(f"üéØ Both Tiger and Goat agents analyzed")
        print("\nüîç Key Insights:")
        print("   - Self-play training dynamics")
        print("   - Competitive balance evolution")
        print("   - Learning efficiency comparison")
        print("   - Strategic development patterns")
        
    else:
        print("‚ùå Could not load training models for analysis")


if __name__ == "__main__":
    main() 